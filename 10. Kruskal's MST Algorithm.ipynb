{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2466fb3e",
   "metadata": {},
   "source": [
    "Question 1\n",
    "\n",
    "clustering1.txt file describes a distance function (equivalently, a complete graph with edge costs).  It has the following format:\n",
    "\n",
    "[number_of_nodes]\n",
    "\n",
    "[edge 1 node 1] [edge 1 node 2] [edge 1 cost]\n",
    "\n",
    "[edge 2 node 1] [edge 2 node 2] [edge 2 cost]\n",
    "\n",
    "...\n",
    "\n",
    "There is one edge (i,j)(i,j) for each choice of 1 <= i <= j <= n, where nn is the number of nodes.\n",
    "\n",
    "For example, the third line of the file is \"1 3 5250\", indicating that the distance between nodes 1 and 3 (equivalently, the cost of the edge (1,3)) is 5250.  You can assume that distances are positive, but you should NOT assume that they are distinct.\n",
    "\n",
    "Your task in this problem is to run the clustering algorithm from lecture on this data set, where the target number kk of clusters is set to 4.  What is the maximum spacing of a 4-clustering?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d78892b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The maximum spacing of a 4-clustering is: \n",
      " 106\n",
      "\n",
      "The run time of Max Spacing of k-Clusterings Algorithm is: 0.18409490585327148 second(s).\n"
     ]
    }
   ],
   "source": [
    "class UFnode:\n",
    "    def __init__(self, node):\n",
    "        \"\"\"\n",
    "            To represent node in Union Find class, which has info of its leader and size\n",
    "        \"\"\"\n",
    "        self.value = node\n",
    "        self.leader = node\n",
    "        self.size = 1\n",
    "       \n",
    "    def __lt__(self, other):\n",
    "        # to use for sorting \n",
    "        return self.value < other.value\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f\"{self.value}\"\n",
    "        \n",
    "\n",
    "\n",
    "class Union_find:\n",
    "    def __init__(self, size):\n",
    "        # connected components, dictionary having key as leader and corresponding list of nodes that point to the leader\n",
    "        self.clusters = {i: [i] for i in range(1, size + 1)}   \n",
    "        self.count = size     # track the count of clusters, initiate as the total count of nodes\n",
    "        self.nodes = {i: UFnode(i) for i in range(1, size + 1)}   # storage of nodes\n",
    "        \n",
    "    def get_size(self, node):\n",
    "        # node is an int\n",
    "        return self.nodes[node].size\n",
    "    \n",
    "    def find(self, node):\n",
    "        # node is an int\n",
    "        # returns leader vertex, since each vertex points to its leader and leader vertex points to itself\n",
    "        return self.nodes[node].leader\n",
    "    \n",
    "    \n",
    "    def union(self, node1, node2):\n",
    "        \"\"\"\n",
    "            Merge two components that node 1 and node 2 are in, have the smaller one inherit the leader of the large one\n",
    "            Then reduce the cluster count by 1\n",
    "            node 1 and node 2 are ints\n",
    "        \"\"\"\n",
    "        \n",
    "        if self.get_size(node1) >= self.get_size(node2):\n",
    "            larger_leader = self.find(node1)\n",
    "            smaller_leader = self.find(node2)\n",
    "            \n",
    "                \n",
    "        else:\n",
    "            smaller_leader = self.find(node1)\n",
    "            larger_leader = self.find(node2)\n",
    "        \n",
    "        # change leader pointer of nodes in smaller cluster to point to the leader of larger cluster, update size of larger \n",
    "        # cluster, and append nodes in smaller cluster to larger cluster, then delete the smaller cluster\n",
    "            \n",
    "        for node in self.clusters[smaller_leader]:\n",
    "            self.nodes[node].leader = larger_leader\n",
    "            self.nodes[larger_leader].size += 1\n",
    "            self.clusters[larger_leader].append(node)\n",
    "            \n",
    "        del self.clusters[smaller_leader]\n",
    "        \n",
    "        # reduce one cluster count after union\n",
    "        self.count -= 1\n",
    "        \n",
    "        \n",
    "    def check_cycle(self, node1, node2):\n",
    "        # if node 1 and node 2 have the same leader, meaning they are in the same cluster\n",
    "        # node1 and node2 are ints\n",
    "        return self.find(node1) == self.find(node2)\n",
    "\n",
    "    \n",
    "class Graph:\n",
    "    def __init__(self, node_count):\n",
    "        self.edges = []       # list of edges in the form of (cost, node1, node2)\n",
    "        self.edge_count = 0\n",
    "        self.node_count = node_count\n",
    "    \n",
    "    def max_space(self, k):\n",
    "        \n",
    "        \"\"\"\n",
    "            Algorithm to find the maximum spacing of k-clustering using Union Find Data Structure\n",
    "        \"\"\"\n",
    "        \n",
    "        self.edges.sort()\n",
    "        \n",
    "        uf = Union_find(self.node_count)\n",
    "        \n",
    "        if k > uf.count:\n",
    "            return f\"You need to pick a cluster count less than {uf.count}!\"\n",
    "        \n",
    "        else:\n",
    "            # merge clusters starting from the smallest edge, stop when there's k clusters remaining, \n",
    "            # that is before the final k - 1 clusters is formed\n",
    "            for i in range(self.edge_count):\n",
    "                cost, node1, node2 = self.edges[i]\n",
    "                \n",
    "                if not uf.check_cycle(node1, node2):\n",
    "                    if uf.count == k:\n",
    "                        return cost\n",
    "                    else:\n",
    "                        uf.union(node1, node2)\n",
    "                    \n",
    "                \n",
    "\n",
    "\n",
    "def load(filename):\n",
    "    \"\"\"\n",
    "        Load data in file to a graph using Graph class\n",
    "    \"\"\"\n",
    "    with open(filename) as file:\n",
    "        f = file.readlines()\n",
    "        \n",
    "        # extract the first line to be node_count\n",
    "        node_count = f[0].strip()\n",
    "        node_count = int(node_count)\n",
    "        \n",
    "        graph = Graph(node_count)\n",
    "        \n",
    "        # read the rest of lines to tuple of (cost, node1, node2) and add to the Graph.edges\n",
    "        for lines in f[1:]:\n",
    "            node1, node2, cost = lines.strip().rsplit(\" \")\n",
    "            graph.edges.append((int(cost), int(node1), int(node2)))\n",
    "            graph.edge_count += 1\n",
    "            \n",
    "    return graph\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    import time\n",
    "    start = time.time()\n",
    "    graph = load(\"clustering1.txt\")\n",
    "    print(\"The maximum spacing of a 4-clustering is: \\n\", graph.max_space(4))\n",
    "    end = time.time()\n",
    "    print()\n",
    "    print(f\"The run time of Max Spacing of k-Clusterings Algorithm is: {end-start} second(s).\")\n",
    "\n",
    "\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a10a9fd1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "98ce6096",
   "metadata": {},
   "source": [
    "Question 2\n",
    "\n",
    "In this question your task is again to run the clustering algorithm from lecture, but on a MUCH bigger graph.  So big, in fact, that the distances (i.e., edge costs) are only defined implicitly, rather than being provided as an explicit list.\n",
    "\n",
    "The data set is in clustering_big.txt\n",
    "\n",
    "The format is:\n",
    "\n",
    "[# of nodes] [# of bits for each node's label]\n",
    "\n",
    "[first bit of node 1] ... [last bit of node 1]\n",
    "\n",
    "[first bit of node 2] ... [last bit of node 2]\n",
    "\n",
    "...\n",
    "\n",
    "For example, the third line of the file \"0 1 1 0 0 1 1 0 0 1 0 1 1 1 1 1 1 0 1 0 1 1 0 1\" denotes the 24 bits associated with node #2.\n",
    "\n",
    "The distance between two nodes uu and vv in this problem is defined as the Hamming distance--- the number of differing bits --- between the two nodes' labels.  For example, the Hamming distance between the 24-bit label of node #2 above and the label \"0 1 0 0 0 1 0 0 0 1 0 1 1 1 1 1 1 0 1 0 0 1 0 1\" is 3 (since they differ in the 3rd, 7th, and 21st bits).\n",
    "\n",
    "The question is: what is the largest value of k such that there is a k-clustering with spacing at least 3?  That is, how many clusters are needed to ensure that no pair of nodes with all but 2 bits in common get split into different clusters?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "853a9984",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to read the file is:  1.6737103462219238\n",
      "Time to create bit mask is:  0.0\n",
      "\n",
      "The largest value of k such that there is a k-clustering with spacing at least 3 is:\n",
      " 6118\n",
      "\n",
      "The run time of the algorithm is: 28.55481481552124 second(s)\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import itertools as it\n",
    "from networkx.utils import UnionFind\n",
    "\n",
    "def load2(filename):\n",
    "    \"\"\"\n",
    "        Load data in file\n",
    "        returns:\n",
    "        node_count: total count of nodes in the file\n",
    "        bit_count: total count of bits\n",
    "        ints_to_nodes: a map that has ints that converted from bits as key and node value as value\n",
    "    \"\"\"\n",
    "    ints_to_nodes = {}\n",
    "    with open(filename) as file:\n",
    "        f = file.readlines()\n",
    "        \n",
    "        # extract the first line to be node_count\n",
    "        node_count, bit_count = f[0].strip().rsplit(\" \")\n",
    "        node_count = int(node_count)\n",
    "        bit_count = int(bit_count)\n",
    "        \n",
    "        # read the rest of lines to tuple of (cost, node1, node2) and add to the Graph.edges\n",
    "        for i in range(1, len(f)):\n",
    "            num = int(re.sub(r\"[\\n\\t\\s]*\", \"\", f[i]), 2)\n",
    "            try:\n",
    "                ints_to_nodes[num] =+ (i,)\n",
    "            except:\n",
    "                ints_to_nodes[num] = (i,)\n",
    "            \n",
    "            \n",
    "    return node_count, bit_count, ints_to_nodes\n",
    "\n",
    "\n",
    "def create_bit_mask(n_bit):\n",
    "    \"\"\"\n",
    "        To creat an array of bit-masks for the distances 0, 1, 2 by doing bit-shifts.\n",
    "    \"\"\"\n",
    "    \n",
    "    bit_mask = {0}\n",
    "    \n",
    "    # create bit_mask for distance as 1\n",
    "    bit_mask.update([1 << i for i in range(n_bit)])\n",
    "    \n",
    "    # create bit_mask for distance as 2\n",
    "    positions = list(it.combinations(range(n_bit), 2))            # create a list of position of 2 bits combination\n",
    "    new_bits = [(1 << position1) + (1 << position2) for position1, position2 in positions]   #calculate the digits based on the list\n",
    "    bit_mask.update(new_bits)\n",
    "    \n",
    "    return bit_mask\n",
    "        \n",
    "    \n",
    "    \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    \"\"\"\n",
    "        Basic idea is create a ints_to_nodes map and a bit_mask. Then use the keys in ints_to_nodes map and bit_mask to\n",
    "        calculate the number = key ^ bit_mask, if the number is in map, union the nodes in the map for both number and the key. \n",
    "        After union all, the length of Union Find data structure is the maximum clustering\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    import time\n",
    "    \n",
    "    start = time.time()\n",
    "    \n",
    "    node_count, bit_count, ints_to_nodes = load2(\"clustering_big.txt\")\n",
    "    \n",
    "    end = time.time()\n",
    "    \n",
    "    print(\"Time to read the file is: \", end-start)\n",
    "    \n",
    "    start = time.time()\n",
    "    \n",
    "    uf = UnionFind()\n",
    "    bit_mask = []\n",
    "    bit_mask = create_bit_mask(bit_count)\n",
    "    \n",
    "    end = time.time()\n",
    "    \n",
    "    print(\"Time to create bit mask is: \", end-start)\n",
    "    \n",
    "    start = time.time()\n",
    "    \n",
    "    for distance in bit_mask:\n",
    "        for key1 in ints_to_nodes.keys():\n",
    "            key2 = key1^distance\n",
    "            try:\n",
    "                uf.union(ints_to_nodes[key1], ints_to_nodes[key2])\n",
    "            except:\n",
    "                continue\n",
    "                \n",
    "    end = time.time()\n",
    "    print()\n",
    "    print(\"The largest value of k such that there is a k-clustering with spacing at least 3 is:\\n\", len(list(uf.to_sets())))\n",
    "    print()\n",
    "    print(f\"The run time of the algorithm is: {end - start} second(s)\")\n",
    "                \n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
