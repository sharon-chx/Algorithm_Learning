{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b7cdb0f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The original heap of data is: \n",
      " [(121, [2], <__main__.Node object at 0x0000018BA9A13910>), (144, [9], <__main__.Node object at 0x0000018BA9AD4310>), (153, [7], <__main__.Node object at 0x0000018BA9AD4250>), (378, [5], <__main__.Node object at 0x0000018BA9AAED60>), (589, [11], <__main__.Node object at 0x0000018BA9AD43D0>), (301, [12], <__main__.Node object at 0x0000018BA9AD4430>), (188, [3], <__main__.Node object at 0x0000018BA9AAE910>), (953, [4], <__main__.Node object at 0x0000018BA9AAEEE0>), (579, [8], <__main__.Node object at 0x0000018BA9AD42B0>), (895, [1], <__main__.Node object at 0x0000018BA9A9E820>), (727, [10], <__main__.Node object at 0x0000018BA9AD4370>), (849, [6], <__main__.Node object at 0x0000018BA9AAE070>), (442, [13], <__main__.Node object at 0x0000018BA9AD4490>), (327, [14], <__main__.Node object at 0x0000018BA9AD44F0>), (930, [15], <__main__.Node object at 0x0000018BA9AD4550>)] \n",
      "\n",
      "The maximum length of a codeword is:  6\n",
      "The minimum length of a codeword is:  3\n",
      "\n",
      "The Huffman Codes for all words are: \n",
      ": {1: '100', 2: '001111', 3: '000110', 4: '010', 5: '1111', 6: '101', 7: '000111', 8: '0010', 9: '001110', 10: '110', 11: '0000', 12: '00110', 13: '1110', 14: '00010', 15: '011'}\n",
      "\n",
      "The Huffman codes is:  000110100010011001110\n",
      "The decoded string is:  314159\n"
     ]
    }
   ],
   "source": [
    "import heapq as hq\n",
    "\n",
    "class Node:\n",
    "    \"\"\"\n",
    "        To represent a node with its value, pointer to left child and pointer to right child\n",
    "    \"\"\"\n",
    "    def __init__(self, value):\n",
    "        self.value = value\n",
    "        self.left = None\n",
    "        self.right = None\n",
    "        \n",
    "    def __str__(self):\n",
    "        return f\"{self.value}\"\n",
    "\n",
    "\n",
    "class Huffman:\n",
    "    \"\"\"\n",
    "        A data structure of binary prex-free encoding tree for a given set of character by their frequencies.\n",
    "        The higher frequencies, the closer to the root the character is.\n",
    "    \"\"\"\n",
    "    def __init__(self, data, node_count):\n",
    "        self.data = data     #holder of data to be processed\n",
    "        self.merge_count = {i: 0 for i in range(1, node_count + 1)}    #keep track of merge count of each node\n",
    "        self.codes = {i:\"\" for i in range(1, node_count + 1)}    #keep track of the Huffman codes of each node\n",
    "        \n",
    "        \n",
    "    def merge(self):\n",
    "        \"\"\"\n",
    "            Pop two elements from heap, merge these two nodes, meaning new weight is the total weights and add two nodes to \n",
    "            one list in decending order of weight, and create a new combining nodes in both subtrees. \n",
    "            Then push the new weigth, new list of nodes, and new tree back to heap.\n",
    "            Also updates the merge_count of each node that getting merged\n",
    "        \"\"\"\n",
    "        \n",
    "        # Pop from the heap\n",
    "        weight1, node_list1, node1 = hq.heappop(self.data) \n",
    "        weight2, node_list2, node2 = hq.heappop(self.data)\n",
    "        \n",
    "        # initiate the parent node for merge two node branches\n",
    "        new_node = Node(\"parent\")\n",
    "        \n",
    "        # also add 1 to merge_count of each node in node1 and node2\n",
    "        for node in node_list1:\n",
    "            self.merge_count[node] += 1\n",
    "        for node in node_list2:\n",
    "            self.merge_count[node] += 1  \n",
    "        \n",
    "        if len(node_list1) ==1 and len(node_list2) != 1:\n",
    "            small_node = node_list2\n",
    "            large_node = node_list1\n",
    "            # create a new tree with subtree of smaller weight on the right, and subtree of larger weight on the left\n",
    "            new_node.left = node1\n",
    "            new_node.right = node2\n",
    "        else:\n",
    "            small_node = node_list1\n",
    "            large_node = node_list2\n",
    "            # create a new tree with subtree of smaller weight on the right, and subtree of larger weight on the left\n",
    "            new_node.left = node2\n",
    "            new_node.right = node1\n",
    "        \n",
    "        # combine weights and node list, then push new weight, new node list, and new tree back to heap\n",
    "        new_weight = weight1 + weight2\n",
    "        new_node_list = large_node + small_node\n",
    "        hq.heappush(self.data, (new_weight, new_node_list, new_node))\n",
    "        \n",
    "        # add a bit in the front of correspond codes of each node that just got merged, to come up with the final Huffman code\n",
    "        for node in small_node:\n",
    "            self.codes[node] = '1' + self.codes[node]\n",
    "        for node in large_node:\n",
    "            self.codes[node] = '0' + self.codes[node]\n",
    "         \n",
    "        \n",
    "    def create_tree(self):\n",
    "        \"\"\"\n",
    "            Returns the Binary Tree of Huffman Codes; Return error message if not all the nodes have been merged\n",
    "        \"\"\"\n",
    "        if len(self.data) != 1:\n",
    "            print(\"Something went wrong! Not ready for creating tree yet\")\n",
    "            \n",
    "        else:\n",
    "            self.tree = self.data[0][2]\n",
    "                \n",
    "                \n",
    "    def huffman_algorithm(self):\n",
    "        \"\"\"\n",
    "            The complete Huffman's Algorithm\n",
    "        \"\"\"\n",
    "        # merge nodes till only two group of nodes left\n",
    "        while len(self.data) > 1:\n",
    "            self.merge()\n",
    "        \n",
    "        self.create_tree()\n",
    "        \n",
    "        \n",
    "    def max_len(self):\n",
    "        # returns maximum length of a encoded character\n",
    "        return max(self.merge_count.values())\n",
    "    \n",
    "    \n",
    "    def min_len(self):\n",
    "        # returns minimum length of a encoded character\n",
    "        return min(self.merge_count.values())\n",
    "        \n",
    "    \n",
    "    def decode(self, string):\n",
    "        \"\"\"\n",
    "            To decode a string provided. If the char is 0, go to left child; if the char is 1, go to right child.\n",
    "            Once found a value, add to result and restart the search from the root of the tree.\n",
    "        \"\"\"\n",
    "        result = \"\"\n",
    "        temp = self.get_tree()\n",
    "        for bit in string:\n",
    "            if bit == '0':\n",
    "                temp = temp.left\n",
    "                if temp.value != \"parent\":\n",
    "                    result += str(temp.value)\n",
    "                    temp = self.tree\n",
    "            elif bit == '1':\n",
    "                temp = temp.right\n",
    "                if temp.value != \"parent\":\n",
    "                    result += str(temp.value)\n",
    "                    temp = self.tree\n",
    "            else:\n",
    "                return \"The string you entered must only have 1 or 0!!\"\n",
    "\n",
    "        return result\n",
    "    \n",
    "    def get_tree(self):\n",
    "        \"\"\"\n",
    "            Return the Huffman Codes binary tree\n",
    "        \"\"\"\n",
    "        return self.data[0][2]\n",
    "         \n",
    "    \n",
    "def load(filename):\n",
    "    \"\"\"\n",
    "        To load data to a heap with tuple (key, [node(s)], tree) inside\n",
    "        Returns the heap\n",
    "    \"\"\"\n",
    "    # initiate a empty heap\n",
    "    data = []\n",
    "    \n",
    "    with open(filename) as file:\n",
    "        f = file.readlines()\n",
    "        \n",
    "        # extract the first line to be node_count\n",
    "        node_count= int(f[0].strip())\n",
    "        \n",
    "        # read the rest of lines to heap as (line value, line number, tree), which is (weight, node, Node(i))\n",
    "        for i in range(1, len(f)):\n",
    "            hq.heappush(data, (int(f[i].strip()), [i], Node(i)))\n",
    "        \n",
    "    return node_count, data\n",
    "        \n",
    "        \n",
    "        \n",
    "if __name__ == \"__main__\":\n",
    "    node_count, data = load(\"test.txt\")\n",
    "    print(\"The original heap of data is: \\n\", data, \"\\n\")\n",
    "    \n",
    "    huffman = Huffman(data, node_count)\n",
    "    huffman.huffman_algorithm()\n",
    "    print(\"The maximum length of a codeword is: \", huffman.max_len())\n",
    "    print(\"The minimum length of a codeword is: \", huffman.min_len())\n",
    "    print()\n",
    "    \n",
    "    print(\"The Huffman Codes for all words are: \\n:\", huffman.codes)\n",
    "    print()\n",
    "    \n",
    "    string = '000110100010011001110'\n",
    "    print(\"The Huffman codes is: \", string)\n",
    "    print(\"The decoded string is: \", huffman.decode(string))\n",
    "    \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f31cc457",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7320b353",
   "metadata": {},
   "source": [
    "Question 1 & 2\n",
    "\n",
    "In this programming problem and the next you'll code up the greedy algorithm from the lectures on Huffman coding using huffman.txt\n",
    "\n",
    "This file describes an instance of the problem. It has the following format:\n",
    "\n",
    "[number_of_symbols]\n",
    "\n",
    "[weight of symbol #1]\n",
    "\n",
    "[weight of symbol #2]\n",
    "\n",
    "...\n",
    "\n",
    "For example, the third line of the file is \"6852892,\" indicating that the weight of the second symbol of the alphabet is 6852892.  (We're using weights instead of frequencies, like in the \"A More Complex Example\" video.)\n",
    "\n",
    "Your task in this problem is to run the Huffman coding algorithm from lecture on this data set. What is the maximum length of a codeword in the resulting Huffman code?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "18ae5a7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The maximum length of a codeword is:  19\n",
      "The minimum length of a codeword is:  9\n",
      "The run time of Huffman's Algorithm is 0.007946968078613281 second(s). \n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "    \n",
    "start = time.time()\n",
    "\n",
    "node_count, data = load(\"huffman.txt\")\n",
    "huffman = Huffman(data, node_count)\n",
    "huffman.huffman_algorithm()    \n",
    "print(\"The maximum length of a codeword is: \", huffman.max_len())\n",
    "print(\"The minimum length of a codeword is: \", huffman.min_len())\n",
    "\n",
    "end = time.time()\n",
    "print(f\"The run time of Huffman's Algorithm is {end-start} second(s). \")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bdf1bd9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "309b960f",
   "metadata": {},
   "source": [
    "Question 3\n",
    "\n",
    "In this programming problem you'll code up the dynamic programming algorithm for computing a maximum-weight independent set of a path graph using mwis.txt\n",
    "\n",
    "This file describes the weights of the vertices in a path graph (with the weights listed in the order in which vertices appear in the path). It has the following format:\n",
    "\n",
    "[number_of_vertices]\n",
    "\n",
    "[weight of first vertex]\n",
    "\n",
    "[weight of second vertex]\n",
    "\n",
    "...\n",
    "\n",
    "For example, the third line of the file is \"6395702,\" indicating that the weight of the second vertex of the graph is 6395702. \n",
    "\n",
    "Your task in this problem is to run the dynamic programming algorithm (and the reconstruction procedure) from lecture on this data set.  The question is: of the vertices 1, 2, 3, 4, 17, 117, 517, and 997, which ones belong to the maximum-weight independent set?  (By \"vertex 1\" we mean the first vertex of the graph---there is no vertex 0.)   In the box below, enter a 8-bit string, where the ith bit should be 1 if the ith of these 8 vertices is in the maximum-weight independent set, and 0 otherwise. For example, if you think that the vertices 1, 4, 17, and 517 are in the maximum-weight independent set and the other four vertices are not, then you should enter the string 10011010 in the box below.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f7844727",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The maximum total weight of a max-weight IS of the data set is: \n",
      " 2955353732 \n",
      "\n",
      "The vertices in the max-weight IS of the data set is: \n",
      " [1000, 998, 995, 993, 991, 989, 987, 985, 983, 981, 979, 977, 975, 973, 971, 969, 966, 964, 962, 960, 958, 956, 954, 952, 950, 948, 946, 944, 942, 940, 938, 936, 934, 932, 929, 927, 924, 921, 919, 917, 915, 913, 911, 909, 907, 905, 903, 900, 898, 896, 894, 892, 890, 888, 886, 884, 882, 880, 878, 876, 873, 871, 868, 866, 864, 861, 859, 857, 855, 853, 851, 849, 846, 843, 841, 839, 837, 834, 832, 829, 827, 825, 823, 821, 819, 816, 814, 812, 809, 806, 803, 801, 799, 797, 795, 793, 790, 788, 786, 784, 781, 778, 776, 774, 772, 770, 768, 766, 763, 760, 757, 755, 752, 750, 748, 745, 743, 741, 739, 737, 735, 733, 730, 728, 726, 723, 721, 719, 717, 715, 713, 710, 708, 706, 704, 702, 699, 697, 695, 692, 690, 688, 686, 684, 682, 679, 676, 673, 671, 669, 666, 664, 662, 660, 658, 656, 654, 652, 649, 647, 645, 643, 641, 639, 637, 634, 632, 630, 628, 625, 623, 621, 619, 617, 615, 613, 610, 608, 606, 604, 602, 600, 598, 596, 594, 592, 590, 588, 586, 584, 581, 579, 577, 575, 573, 571, 569, 566, 563, 560, 558, 556, 554, 552, 550, 548, 545, 543, 541, 539, 537, 534, 531, 529, 527, 525, 523, 521, 519, 517, 514, 512, 510, 508, 505, 503, 500, 498, 496, 494, 492, 490, 488, 485, 483, 481, 478, 476, 474, 472, 470, 468, 466, 464, 462, 460, 458, 456, 454, 451, 449, 447, 445, 443, 441, 439, 437, 435, 433, 431, 429, 427, 425, 422, 420, 417, 415, 413, 410, 408, 406, 404, 402, 399, 397, 395, 393, 391, 389, 387, 385, 383, 381, 379, 377, 375, 373, 371, 369, 367, 365, 363, 361, 359, 357, 355, 353, 351, 349, 347, 345, 343, 341, 339, 337, 335, 333, 331, 329, 327, 325, 323, 321, 318, 316, 314, 312, 310, 308, 306, 304, 302, 300, 298, 296, 294, 292, 289, 287, 285, 283, 281, 279, 277, 275, 273, 271, 269, 267, 265, 263, 261, 258, 256, 254, 252, 249, 247, 245, 243, 240, 238, 236, 234, 232, 230, 228, 226, 223, 221, 218, 216, 214, 211, 209, 207, 205, 203, 201, 199, 197, 195, 193, 190, 187, 185, 183, 181, 179, 177, 175, 173, 170, 168, 166, 164, 162, 160, 157, 155, 153, 151, 149, 147, 145, 143, 141, 139, 136, 133, 131, 128, 126, 124, 122, 120, 117, 115, 112, 110, 108, 106, 103, 100, 98, 96, 94, 92, 90, 88, 85, 83, 81, 79, 77, 75, 72, 69, 66, 64, 62, 60, 58, 56, 54, 52, 50, 48, 46, 44, 42, 40, 38, 36, 33, 31, 28, 26, 24, 22, 20, 18, 15, 13, 10, 8, 5, 3, 1] \n",
      "\n",
      "The run time of WIS in Path Graphs Algorithm using Dynamic Programming is: 0.001995086669921875 seconds. \n",
      "\n",
      "Vertex 1 is in maximum-weight independent set?  True\n",
      "Vertex 2 is in maximum-weight independent set?  False\n",
      "Vertex 3 is in maximum-weight independent set?  True\n",
      "Vertex 4 is in maximum-weight independent set?  False\n",
      "Vertex 17 is in maximum-weight independent set?  False\n",
      "Vertex 117 is in maximum-weight independent set?  True\n",
      "Vertex 517 is in maximum-weight independent set?  True\n",
      "Vertex 997 is in maximum-weight independent set?  False\n"
     ]
    }
   ],
   "source": [
    "def load1(filename):\n",
    "    \"\"\"\n",
    "        To load data to a list where index is vertex number, and value is the weight of the vertex\n",
    "        First element of the list is the count of vertices\n",
    "        Returns the list\n",
    "    \"\"\"\n",
    "    # initiate a empty list\n",
    "    data = []\n",
    "    \n",
    "    with open(filename) as file:\n",
    "        for item in file:\n",
    "            data.append(int(item.strip()))\n",
    "        \n",
    "    return data\n",
    "\n",
    "\n",
    "def maximum_weight(lis):\n",
    "    \"\"\"\n",
    "        Find the maximum weight of the max-weight independent set in a given lis, where index is vertex number,\n",
    "        and value is the weight of the vertex, and first elment of list is vertex count.\n",
    "        \n",
    "        Dynamic programming: A[i] = max{ A[i-1] , A[i-2] + weight of i }\n",
    "                meaning when visit each vertex, only two possible cases:\n",
    "                    Case 1 - max-wt IS of G(i-1) is still the max weight\n",
    "                    Case 2 - max-wt IS of G(i-2) + vertex i is the new max weight\n",
    "        \n",
    "        Returns the maximum weight list, and the maximum weight\n",
    "    \"\"\"\n",
    "    max_value = [0, lis[1]]\n",
    "    for i in range(2, len(lis)):\n",
    "        max_value.append(max(max_value[i-1], max_value[i-2] + lis[i]))\n",
    "    return max_value, max_value[-1]\n",
    "\n",
    "\n",
    "def max_wis(lis, max_list):\n",
    "    \"\"\"\n",
    "        Find the vertices of the max-weight independent set based on maximum value list from above function\n",
    "        and the original data lis, where index is vertex number, and value is the weight of the vertex, \n",
    "        and first elment of list is vertex count.\n",
    "        Returns the vertices in a list in backward orders.\n",
    "    \"\"\"\n",
    "    vertices = []\n",
    "    i = len(lis) - 1\n",
    "    while i >= 1:\n",
    "        if max_list[i-1] >= max_list[i-2] + lis[i]:\n",
    "            i -= 1\n",
    "        else:\n",
    "            vertices.append(i)\n",
    "            i -= 2\n",
    "    return vertices\n",
    "        \n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    import time\n",
    "    start = time.time()\n",
    "    \n",
    "    data = load1(\"mwis.txt\")\n",
    "    max_list, max_value = maximum_weight(data)\n",
    "    print(\"The maximum total weight of a max-weight IS of the data set is: \\n\", max_value, \"\\n\")\n",
    "    max_weight_is = max_wis(data, max_list)\n",
    "    print(\"The vertices in the max-weight IS of the data set is: \\n\", max_weight_is, \"\\n\")\n",
    "    \n",
    "    end = time.time()\n",
    "    print(f\"The run time of WIS in Path Graphs Algorithm using Dynamic Programming is: {end-start} seconds. \\n\")\n",
    "\n",
    "    print(f\"Vertex {1} is in maximum-weight independent set?  {1 in max_weight_is}\")\n",
    "    print(f\"Vertex {2} is in maximum-weight independent set?  {2 in max_weight_is}\")\n",
    "    print(f\"Vertex {3} is in maximum-weight independent set?  {3 in max_weight_is}\")\n",
    "    print(f\"Vertex {4} is in maximum-weight independent set?  {4 in max_weight_is}\")\n",
    "    print(f\"Vertex {17} is in maximum-weight independent set?  {17 in max_weight_is}\")\n",
    "    print(f\"Vertex {117} is in maximum-weight independent set?  {117 in max_weight_is}\")\n",
    "    print(f\"Vertex {517} is in maximum-weight independent set?  {517 in max_weight_is}\")\n",
    "    print(f\"Vertex {997} is in maximum-weight independent set?  {997 in max_weight_is}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
